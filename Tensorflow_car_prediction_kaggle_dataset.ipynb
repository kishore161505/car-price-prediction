{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltBpIOaKTUYj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf### models\n",
        "import pandas as pd ### reading and processing data\n",
        "import seaborn as sns ### visualization\n",
        "import numpy as np### math computations\n",
        "import matplotlib.pyplot as plt### plotting bar chart\n",
        "from tensorflow.keras.layers import Normalization, Dense, InputLayer\n",
        "from tensorflow.keras.losses import MeanSquaredError, Huber, MeanAbsoluteError\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AWKNmeXTUVE"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dpt1EAswTUR5"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wljJkPgaTULm"
      },
      "outputs": [],
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/mayankpatel14/second-hand-used-cars-data-set-linear-regression\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jDfmV2tTUIi"
      },
      "outputs": [],
      "source": [
        "os.listdir(\"second-hand-used-cars-data-set-linear-regression\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4MCeC-3pKft"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"second-hand-used-cars-data-set-linear-regression/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Iw5Gw3ypKcT"
      },
      "outputs": [],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2Om6BkdpKZv"
      },
      "outputs": [],
      "source": [
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B_SicL_WpKXH"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(train_df[['v.id', 'on road old', 'on road now', 'years', 'km', 'rating', 'condition', 'economy', 'top speed', 'hp', 'torque', 'current price']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dUoWV7_pKUU"
      },
      "outputs": [],
      "source": [
        "tensor_data = tf.constant(train_df)\n",
        "tensor_data = tf.cast(tensor_data, tf.float32)\n",
        "\n",
        "print(tensor_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeMKGKwQpKRe"
      },
      "outputs": [],
      "source": [
        "tensor_data = tf.random.shuffle(tensor_data)\n",
        "print(tensor_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7HhTYaAIdj0"
      },
      "outputs": [],
      "source": [
        "tensor_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwlUU3BiH3FE"
      },
      "outputs": [],
      "source": [
        "X = tensor_data[:,3:-1]\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnvIU0ieH3Bi"
      },
      "outputs": [],
      "source": [
        "Y = tensor_data[:, -1]\n",
        "print(Y[:5].shape)\n",
        "Y = tf.expand_dims(Y, axis = -1)\n",
        "print(Y[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MUNF39OH29f"
      },
      "outputs": [],
      "source": [
        "normalizer = Normalization(axis = -1, mean= 5, variance = 4)\n",
        "x_normalized = tf.constant([[3,4,5,6,7,8],\n",
        "                            [4,5,6,7,8,9]])\n",
        "normalizer(x_normalized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVyIOjC5pKOk"
      },
      "outputs": [],
      "source": [
        "normalizer = Normalization()\n",
        "normalizer.adapt(X)\n",
        "normalizer(X)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nGG9p0bpKL_"
      },
      "outputs": [],
      "source": [
        "Train_Ratio = 0.8\n",
        "Val_Ratio = 0.1\n",
        "Test_Ratio = 0.1\n",
        "Dataset_Size = len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-A2vVTSMhjg"
      },
      "outputs": [],
      "source": [
        "x_train = X[:int(Dataset_Size * Train_Ratio)]\n",
        "y_train = Y[:int(Dataset_Size * Train_Ratio)]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "to_GSKHZMhf7"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration = True).batch(32).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIfwuRtCMhdf"
      },
      "outputs": [],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2y1KNLf26D0"
      },
      "outputs": [],
      "source": [
        "print(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "saf2dxhz26AO"
      },
      "outputs": [],
      "source": [
        "x_val = X[int(Dataset_Size * Train_Ratio): int(Dataset_Size * (Train_Ratio + Val_Ratio))]\n",
        "y_val = Y[int(Dataset_Size * Train_Ratio): int(Dataset_Size * (Train_Ratio + Val_Ratio))]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUszTZYv259v"
      },
      "outputs": [],
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration = True).batch(32).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa9F88RW257E"
      },
      "outputs": [],
      "source": [
        "x_test = X[int(Dataset_Size*(Train_Ratio + Val_Ratio)):]\n",
        "y_test = Y[int(Dataset_Size* (Train_Ratio+ Val_Ratio)):]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG45qFey6ZxP"
      },
      "outputs": [],
      "source": [
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration = True).batch(32).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btAPD3U56Zts"
      },
      "outputs": [],
      "source": [
        "normalizer = Normalization()\n",
        "normalizer.adapt(x_train)\n",
        "normalizer(x_train)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgtmMYPE6ZrO"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    InputLayer(input_shape = (8,)),\n",
        "    normalizer,\n",
        "    Dense(128, activation = \"relu\"),\n",
        "    Dense(128, activation = \"relu\"),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dense(1),\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbDtV54P6Zou"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model, to_file = \"model.png\", show_shapes = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l3_RPp105Bl"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = Adam(learning_rate = 0.1),\n",
        "              loss = MeanAbsoluteError(),\n",
        "              metrics = [MeanAbsoluteError(), MeanSquaredError(), tf.keras.metrics.RootMeanSquaredError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBvplg2B6Zmf"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = Adam(learning_rate = 0.1),\n",
        "              loss = MeanAbsoluteError(),\n",
        "              metrics = [RootMeanSquaredError()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnGTLTLi6Zj4"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, validation_data = val_dataset, epochs = 100, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci9b1n_H6ZhG"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val_loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-7PCge86ZeK"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['root_mean_squared_error'])\n",
        "plt.plot(history.history['val_root_mean_squared_error'])\n",
        "plt.title('model performance')\n",
        "plt.ylabel('rmse')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BIYdDNR2Q_y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hDXEQSR2Q8a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}